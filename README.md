# ğŸ›¡ï¸ VisionGuard

### Modular Object Detection & Training Framework (YOLOv8)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/)
[![YOLOv8](https://img.shields.io/badge/YOLOv8-Ultralytics-purple.svg)](https://github.com/ultralytics/ultralytics)

VisionGuard is a **modular computer vision framework** built on **YOLOv8 (Ultralytics)** and **OpenCV**. It supports image inference, webcam inference, model training, and model comparison, with utilities for logging and reproducibility.

The project is structured to reflect real-world ML pipelines, separating inference, training, utilities, and tools.

---

## ğŸš€ Features (Implemented)

- âœ… Image-based object detection
- âœ… Real-time webcam detection
- âœ… YOLOv8 model training pipeline
- âœ… Model comparison utilities
- âœ… Reproducibility & logging utilities
- âœ… Clean, scalable project structure

---

## ğŸ“ Project Structure

<!-- TREE START -->
<!-- TREE END -->

---

## ğŸ§± Tech Stack

- **Python 3.9+**
- **Ultralytics YOLOv8**
- **OpenCV**
- **PyTorch**
- **NumPy**

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/shaownXjony/visionguard.git
cd visionguard
```

### 2ï¸âƒ£ Create and activate a virtual environment

```bash
python -m venv .venv
```

**Windows:**
```bash
.venv\Scripts\activate
```

**Linux / macOS:**
```bash
source .venv/bin/activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ§  YOLOv8 Model Setup (One-Time)

Download YOLOv8 weights once:

```bash
python -c "from ultralytics import YOLO; YOLO('yolov8n.pt')"
```

After this, all inference runs **offline**.

---

## â–¶ï¸ Usage

### ğŸ–¼ï¸ Image Inference

Run object detection on an image:

```bash
python src/inference/image.py --image path/to/image.jpg
```

**ğŸ“Œ Output:**
- Annotated image saved in `outputs/`

---

### ğŸ¥ Webcam Inference

Run real-time webcam detection:

```bash
python src/inference/webcam.py
```

**Controls:**
- Press **`q`** to quit

---

### ğŸ‹ï¸ Model Training

Train a YOLOv8 model:

```bash
python src/training/train.py
```

**ğŸ“Œ Notes:**
- Uses Ultralytics YOLOv8 defaults
- Training outputs are saved under `runs/` (YOLO default)

---

### ğŸ“Š Model Comparison

Compare different YOLOv8 model variants:

```bash
python src/tools/compare_models.py
```

**Useful for:**
- Speed vs accuracy trade-offs
- Model benchmarking

---

### ğŸ“¥ Download Sample Data

Fetch sample images or datasets:

```bash
python tools/download_samples.py
```

---

## ğŸ§© Utilities

### Logging
- Centralized logging via `utils/logger.py`

### Reproducibility
- Seed control and deterministic behavior via `utils/reproducibility.py`

These utilities help ensure repeatable experiments.

---

## ğŸ“‚ Outputs

- **Inference results** â†’ `outputs/`
- **Trained models** â†’ `runs/` (YOLO default)
- **Custom weights** (optional) â†’ `models/`

---

## ğŸ›£ï¸ Roadmap (Planned)

- â¬œ Streamlit / GUI interface
- â¬œ Video file inference
- â¬œ Config-file-driven parameters
- â¬œ Experiment tracking dashboard
- â¬œ Docker support

---

## ğŸ¤ Contributing

Contributions are welcome.

1. **Fork** the repository
2. **Create** a feature branch
3. **Commit** your changes
4. **Open** a pull request

Keep changes modular and documented.

---

## ğŸ“„ License

This project is licensed under the **MIT License**.  
See the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¤ Author

**Shaown Jony**

- GitHub: [@shaownXjony](https://github.com/shaownXjony)
- Project: [https://github.com/shaownXjony/visionguard](https://github.com/shaownXjony/visionguard)

---

## â­ Final Notes

VisionGuard demonstrates:

- Practical YOLOv8 usage
- Clean ML project structuring
- Separation of inference, training, and utilities
- Reproducibility-aware experimentation

If you find this project useful, consider giving it a **â­**.